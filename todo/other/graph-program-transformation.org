
Прочитав [why-hypergraphs] я был удивлен и обрадован простотой и
мощностью идеи осуществлять вычисления как переписывания графа. Я
обдумывал эту мысль и пришел к нескольким идеям, которые запишу тут:

* Преамбула

  Компьютеры, которые мы используем, по историческим причинам базируются
  на фон-неймановской вычислительной модели; каждый из них можно образно
  представить как многорукого Шиву в библиотеке - своими руками он
  перекладывает книги и карточки ссылающиеся на них (программисты
  понимают что речь идет о указателях) по полкам и ящикам.

  Эта вычислительная модель берет истоки в Машине Тьюринга - формализме,
  который первоначально был создан для уточнения понятия алгоритма.

  Тем, не менее, это не единственная возможная вычислительная модель; я
  могу привести примеры других тьюринг-эквивалентных моделей:
  - Переписывание высказываний, основанное на нормальных алгоритмах
    Маркова и воплощенное в языке Рефал.
  - Модель исчисления индуктивных конструкций, реализованная в языке Coq
  - Модель взаимодействующих последовательных процессов (частично на ней
    основан Erlang), также в том же направлении можно смотреть в сторону
    пи-исчисления
  - Исчисление предикатов - Prolog
  - Лямбда-исчисление - типизированное и нетипизированное - ML, Haskell
  и другие
  - Клеточные автоматы

  Это не полный список, но важным является то, что практически ничего из
  этого не имеет поддержки в железе на сегодняшний момент, несмотря на
  то, что ранее существовали, например, Forth-процессоры и машины
  компании Symbolics, которые нативно исполняли лисп-код.

  Отчасти это положение дел вызвано историческими факторами, важнейший
  из которых, по моему мнению, - закон Мура - больше не является
  актуальным. В связи с этим, мы можем ожидать изменений, направленных
  на улучшение производительности вычислений в том числе и с помощью
  поиска и разработки иных, не фон-неймановских вычислительных
  моделей.

* Проблемы совместимости вычислительных моделей

  Программы, написанные на конвенциональных языках программирования
  уже сейчас нуждаются в распарралеливании - разработчики компиляторов
  и языков программирования работают в этом направлении, но результаты
  пока скромные.

  Компиляторостроители пытаются выяснить по исходному тексту программы
  теоретически распараллеливаемые участки кода и данных, чтобы
  разделить их выполнение по независимым вычислительным юнитам и
  добиться прироста производительности.

  Разрабочики языков программирования (прежде всего функцональных
  языков) стремятся предоставить гарантии свойств (таких как
  независимость по данным, например) отдельных функций или компонентов
  программы и сделать это по возможности статически - т.е. еще на
  этапе преобразования программы в машинный код.

  Однако в любом случае их усилия упираются в архитектуру, которая
  остается фон-неймановской даже при увеличении количества ядер -
  сколько бы многоруких Шив мы не посадили в библиотеку - добиться
  линейного увеличений производительности не получается - Шивы
  начинают конфликтовать между собой.

  Попытки использования аппаратной поддержки других вычислительных
  моделей наталкиваются на проблемы совместимости с унаследованным
  кодом - рынок не примет новый процессор, если на нем не работают
  старые программы. Поэтому крупные разрабочики железа внедряют
  вычислительные модели в своих архитектурах надстраивая новые системы
  команд над старым ядром, что порождает тех еще технологических
  уродцев и в любом случае не дает универсального решения.

  Однако в узких областях, не скованных проблемами совместимости можно
  наблюдать взрывной рост производительности при отказе от старых
  архитектур и переходе к примеру на ASIC - устройства,
  специализированные для выполнения не фон-неймановских программ.

* Причины проблем совместимости

  Отчасти сложившаяся ситуация может быть объяснена тем, что концепции
  вычислительных моделей языков программирования не помещаются в
  голову специалистов по проектировнию процессорных архитектур - и то
  и другое - сложные дисциплины, требующие полного погружения и
  обучения в течении многих лет.

  Обученный специалист, как мне кажется, вероятнее всего старше сорока
  лет, является высокооплачиваемым профессионалом, главой семьи с
  консервативными убеждениями и совершенно не мотивирован изучать с
  нуля смежную область, т.к. такое действие расходится с идеей
  процедурной рациональности. Поэтому можно предположить что такие
  специалисты исключительно редки и не могут создать критическую массу
  мнений для изменения парадигмы внутри своей и смежной областей.

  Даже в случае появления пилотных проектов необходимой направленности
  их шанс на успешную реализацию не очень высок, и любой провал (даже
  по не-технологическим причинам) приводит к дискредитации идеи,
  подобной тому, что теперь называется "Зимой искуственного
  интеллекта".

* Возможные пути решения

  Представим себе набор условий, которые способствовали бы решению
  проблемы увеличения производительности вычислений за счет более
  широкого использования альтернативных вычислительных моделей вместе
  с соответствующей архитектурной поддержкой на уровне железа.

  Во-первых, должен был бы не просто писать программу на известном ему
  языке программирования (С++, Java) под известную ему архитектуру
  (x86) - он должен был бы прямо в момент написания программы
  проектировать и реализовывать эту архитектуру, причем учитывая
  огромное количество ограничений технологии производства процессоров
  и непрерывно проводя бизнес-анализ всего проекта в целом

  Во-вторых, в ответ на изменения требований к продукту (которые
  постоянно меняются) он должен иметь возможность компетентно
  переходить от одной архитектуре к другой так, чтобы стоимость
  преобразования уже написанного (возможно не им) кода приближалась к
  нулю, в идеале была бы совсем бесплатно.

  Излишне объяснять что на текущем уровне компетентности программистов
  и развития средств поддержки программирования - это просто
  невозможно. Мы плавно увеличиваем производительность труда
  программиста за счет более мощных инструментальных средств и новых
  языков, но с высоты поставленной задачи результаты этих усилий
  просто не видны

  Однако все меняется, если мы начинаем использовать элементы AGI как
  инструментальное средство программирования и проектирования. Этот
  подход кажется вполне естественным, т.к. граф выполнения программы -
  это (сюрприз!) именно граф, большинство оптимизаций сводятся к его
  переписыванию, и что самое интересное - мы можем взять все
  программы, доступные нам в качестве исходных текстов, построить по
  ним графы, и на основании всего этого массива данных автоматически
  вычислить наиболее оптимальную архитектуру аппаратных средств,
  учитывая ограничения (технологические и финансово-экономические)
  производства.

  Эта задача видится вычислительно емкой, но довольно несложной - мы
  просто должны протестировать полученный пул программ на всех (или
  основных) вариантах реализумых вычислительных архитектур.
